{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92cef2de",
   "metadata": {},
   "source": [
    "# Clasificador de Carnes\n",
    "\n",
    "## Maestría en Ciberseguridad\n",
    "\n",
    "## Módulo: Tratamiento de Datos\n",
    "\n",
    "### Desarrellado por: Iván Reyes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e87497",
   "metadata": {},
   "source": [
    "#### Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da8b57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ea60d",
   "metadata": {},
   "source": [
    "#### Preparación de ciertos parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa17299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamaño de la Imagen\n",
    "IMG_SIZE = 50\n",
    "#Epocas\n",
    "epochs = 15 \n",
    "#muestras procesadas\n",
    "batch_size = 64\n",
    "#Archivo de almacenamineto del resumen del modelo\n",
    "MODEL_SUMMARY_FILE = \"model_summary.txt\"\n",
    "#Se estandariza el tamaño de las imagenes\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = IMG_SIZE, IMG_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc70a57",
   "metadata": {},
   "source": [
    "#### Preparación  Modelo Secuencial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb3ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255,input_shape = (IMG_SIZE,IMG_SIZE,3)),\n",
    "    Conv2D(16,3,activation='relu',padding='same'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32,3,activation='relu',padding='same'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64,3,activation='relu',padding='same'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(8)\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512041d",
   "metadata": {},
   "source": [
    "#### Almacenar el modelo en archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca5370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(MODEL_SUMMARY_FILE, \"w\") as fh:\n",
    "    model.summary(print_fn=lambda line: fh.write(line + \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db220a4",
   "metadata": {},
   "source": [
    "###### Resumen del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a0e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 50, 50, 3)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 50, 50, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 25, 25, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 25, 25, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 12, 12, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               295040    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 319656 (1.22 MB)\n",
      "Trainable params: 319656 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486bdee",
   "metadata": {},
   "source": [
    "#### Preparación del DataSet \n",
    "\n",
    "#### Data Test\n",
    "\n",
    "#### Data Validation\n",
    "\n",
    "#### Data Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26559aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1633 files belonging to 8 classes.\n",
      "Found 810 images belonging to 8 classes.\n",
      "Found 1633 images belonging to 8 classes.\n",
      "Found 996 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory('./train',seed =123,image_size=(IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "classes_train = train_ds.class_names\n",
    "num_classes = len(classes_train)\n",
    "\n",
    "data_train_generator = ImageDataGenerator()\n",
    "data_validation_generator = ImageDataGenerator()\n",
    "data_test_generator = ImageDataGenerator()\n",
    "\n",
    "test_generator = data_test_generator.flow_from_directory(\n",
    "    './test',\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "train_generator = data_train_generator.flow_from_directory(\n",
    "    './train',\n",
    "    target_size = (IMG_SIZE,IMG_SIZE),\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "validation_generator = data_validation_generator.flow_from_directory(\n",
    "    './validation',\n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be600c5f",
   "metadata": {},
   "source": [
    "#### Se entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c464bb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "52/52 [==============================] - 4s 51ms/step - loss: 1.3211 - accuracy: 0.5769\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 1.0076 - accuracy: 0.6216\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 2s 39ms/step - loss: 0.6101 - accuracy: 0.7581\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.4856 - accuracy: 0.8108\n",
      "Epoch 5/15\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.3864 - accuracy: 0.8518\n",
      "Epoch 6/15\n",
      "52/52 [==============================] - 2s 40ms/step - loss: 0.3814 - accuracy: 0.8512\n",
      "Epoch 7/15\n",
      "52/52 [==============================] - 2s 41ms/step - loss: 0.3936 - accuracy: 0.8420\n",
      "Epoch 8/15\n",
      "52/52 [==============================] - 2s 43ms/step - loss: 0.3233 - accuracy: 0.8836\n",
      "Epoch 9/15\n",
      "52/52 [==============================] - 2s 44ms/step - loss: 0.2705 - accuracy: 0.9045\n",
      "Epoch 10/15\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 0.2199 - accuracy: 0.9277\n",
      "Epoch 11/15\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 0.2654 - accuracy: 0.8953\n",
      "Epoch 12/15\n",
      "52/52 [==============================] - 3s 53ms/step - loss: 0.2826 - accuracy: 0.8934\n",
      "Epoch 13/15\n",
      "52/52 [==============================] - 3s 51ms/step - loss: 0.2067 - accuracy: 0.9284\n",
      "Epoch 14/15\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 0.2103 - accuracy: 0.9308\n",
      "Epoch 15/15\n",
      "52/52 [==============================] - 3s 52ms/step - loss: 0.1714 - accuracy: 0.9363\n"
     ]
    }
   ],
   "source": [
    "classifier_meat = model.fit(train_ds,batch_size=batch_size,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305be60",
   "metadata": {},
   "source": [
    "#### Evaluación del Modelo y generación de matrices de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "589b274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 5s 180ms/step\n",
      "Valores de test correctos 724 de 810\n",
      "Porcentaje valores correctos: 89.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,  43,   0,   5,   0,   0,   0,   0],\n",
       "       [  0,   0,  54,   0,  11,   0,  32,   0],\n",
       "       [  0,   2,   0,  42,   0,   0,   1,   0],\n",
       "       [  0,   1,   2,   0, 448,   0,   5,   3],\n",
       "       [  0,   1,   0,   0,   3,  15,   0,   0],\n",
       "       [  0,   0,   1,   0,   3,   0, 110,   0],\n",
       "       [  0,   0,   1,   0,  14,   0,   0,  12]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicción en test\n",
    "\n",
    "predicted_test = model.predict(test_generator)\n",
    "\n",
    "y_predict_test = np.argmax(predicted_test,axis=1)\n",
    "y_real_test = test_generator.classes\n",
    "correct_test = np.where(y_predict_test==y_real_test)[0]\n",
    "\n",
    "print ('Valores de test correctos %s de %s'%(len(correct_test),len(y_real_test)))\n",
    "print ('Porcentaje valores correctos: %.2f'%(len(correct_test)/len(y_real_test)*100))\n",
    "confusion_matrix(y_real_test, y_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34979db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 6s 108ms/step\n",
      "Valores de train correctos  1530 de 1633\n",
      "Porcentaje valores correctos: 93.69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 59,   0,   1,   0,   0,   2,   0],\n",
       "       [  0, 157,   0,   9,   0,  47,   0],\n",
       "       [  0,   0, 105,   0,   0,   0,   0],\n",
       "       [  0,   2,   0, 937,   0,  10,   0],\n",
       "       [  0,   0,   0,   1,  36,   0,   0],\n",
       "       [  2,   0,   0,   0,   0, 202,   0],\n",
       "       [  0,   0,   0,  29,   0,   0,  34]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicción en train\n",
    "\n",
    "predicted_train = model.predict(train_generator)\n",
    "y_predict_train = np.argmax(predicted_train,axis=1)\n",
    "y_real_train = train_generator.classes\n",
    "correct_train = np.where(y_predict_train==y_real_train)[0]\n",
    "\n",
    "print ('Valores de train correctos  %s de %s'%(len(correct_train),len(y_real_train)))\n",
    "print ('Porcentaje valores correctos: %.2f'%(len(correct_train)/len(y_real_train)*100))\n",
    "confusion_matrix(y_real_train, y_predict_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79160bbd",
   "metadata": {},
   "source": [
    "#### Evaluación Final de Efectividad del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "822b3671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 810 files belonging to 8 classes.\n",
      "52/52 [==============================] - 1s 20ms/step - loss: 0.1298 - accuracy: 0.9522\n",
      "26/26 [==============================] - 1s 18ms/step - loss: 0.3605 - accuracy: 0.8864\n",
      "\n",
      "\n",
      "Accuracy test: 88.64% \n",
      "\n",
      "Accuracy train: 95.22% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory('./test', seed = 123, image_size = (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "\n",
    "train_eval = model.evaluate(train_ds, verbose=1)\n",
    "test_eval = model.evaluate(test_ds, verbose=1)\n",
    "print(\"\\n\")\n",
    "print(f\"Accuracy test: {round(100 * test_eval[1], 2)}% \\n\")\n",
    "print(f\"Accuracy train: {round(100 * train_eval[1], 2)}% \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
